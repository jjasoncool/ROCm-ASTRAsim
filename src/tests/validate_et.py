#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ET æª”æ¡ˆé©—è­‰å·¥å…· - å¢å¼·ç‰ˆ

ç”¨é€”ï¼š
  é€æª”é©—è­‰ Chakra protobuf .etï¼ˆExecution Traceï¼‰æª”æ¡ˆçš„æ­£ç¢ºæ€§ï¼Œä¸¦æä¾›è©³ç´°åˆ†æã€‚

ä¸»è¦åŠŸèƒ½ï¼š
  - åŸºæœ¬é©—è­‰ï¼šæª”æ¡ˆæ ¼å¼ã€protobuf è§£ç¢¼ã€metadata ç‰ˆæœ¬
  - è©³ç´°åˆ†æï¼šç¯€é»é¡å‹çµ±è¨ˆã€é€šè¨Šå¤§å°ã€åŸ·è¡Œæ™‚é–“åˆ†æ
  - æ·±åº¦é©—è­‰ï¼šè·¨ rank ä¸€è‡´æ€§æª¢æŸ¥ã€ç¯€é»å°æ‡‰é—œä¿‚é©—è­‰
  - éŒ¯èª¤æª¢æ¸¬ï¼šæª”æ¡ˆæˆªæ–·ã€æ ¼å¼éŒ¯èª¤ã€æ•¸æ“šä¸ä¸€è‡´

é—œéµç‰¹æ€§ï¼š
  1) å®‰å…¨çš„ protobuf è§£ç¢¼ï¼šé¿å…åœ¨æˆªæ–·æª”æ¡ˆè™•ç„¡é™ç­‰å¾…
  2) å¤šå±¤æ¬¡é©—è­‰ï¼šå¾åŸºæœ¬æ ¼å¼åˆ°æ·±åº¦èªç¾©æª¢æŸ¥
  3) è©³ç´°çµ±è¨ˆï¼šé€šè¨Šæ¨¡å¼ã€æ™‚é–“åˆ†å¸ƒã€ç¯€é»é¡å‹åˆ†æ
  4) è·¨ rank é©—è­‰ï¼šç¢ºä¿åˆ†æ•£å¼è¨“ç·´çš„ä¸€è‡´æ€§

ä½¿ç”¨æ–¹å¼ï¼š
  åŸºæœ¬é©—è­‰ï¼ˆå«è©³ç´°åˆ†æï¼‰ï¼š
    python src/tests/validate_et.py

  æ·±åº¦é©—è­‰ï¼š
    python src/tests/validate_et.py --validate

  é™åˆ¶ç¯€é»æ•¸ï¼ˆå¿«é€Ÿæª¢æŸ¥ï¼‰ï¼š
    python src/tests/validate_et.py --max-nodes 20

  å®Œæ•´åˆ†æï¼š
    python src/tests/validate_et.py --validateè¼¸å‡ºèªªæ˜ï¼š
  ğŸ“ æª”æ¡ˆåŸºæœ¬è³‡è¨Š
  ğŸ” è©³ç´°ç¯€é»åˆ†æ
  âœ… é©—è­‰é€šéé …ç›®
  âš ï¸  æ½›åœ¨å•é¡Œè­¦å‘Š
  âŒ åš´é‡éŒ¯èª¤é …ç›®
"""

import sys
import re
import argparse
from pathlib import Path

# Chakra çš„ protolibï¼šæä¾› encode/decodeMessageï¼ˆé•·åº¦å‰ç¶´çš„ protobuf ä¸²æµï¼‰
from chakra.src.third_party.utils.protolib import decodeMessage as decode_message
# et_def_pb2ï¼šChakra çš„ protobuf schemaï¼ˆNode / GlobalMetadata / å¸¸æ•¸ï¼‰
from chakra.schema.protobuf.et_def_pb2 import (
    GlobalMetadata, Node, ALL_REDUCE, ALL_GATHER, REDUCE_SCATTER, ALL_TO_ALL
)

COMM_NAMES = {
    ALL_REDUCE: "ALL_REDUCE",
    ALL_GATHER: "ALL_GATHER",
    REDUCE_SCATTER: "REDUCE_SCATTER",
    ALL_TO_ALL: "ALL_TO_ALL",
}

# åƒ…åŒ¹é… allreduce.{num}.et æª”åï¼ˆç¢ºä¿æ’åºèˆ‡ rank ä¸€è‡´ï¼‰
PATTERN = re.compile(r"^allreduce\.(\d+)\.et$")


def read_one_et(p: Path, max_nodes: int | None = None, detailed: bool = False):
    """
    è§£ä¸€å€‹ .et æª”ä¸¦å›å‚³ (meta, nodes, total_bytes, kinds, detailed_info)ã€‚

    å®‰å…¨æ€§è¦é»ï¼š
      - å…ˆè¨˜æª”æ¡ˆç¸½é•·åº¦ sizeï¼Œåƒ…åœ¨ f.tell() < size æ™‚è§£ä¸‹ä¸€ç­†ï¼Œé¿å…åœ¨ EOF è™• decode è€Œå¡ä½ã€‚
      - æ¯ç­†è§£å®Œå¾Œæª¢æŸ¥ä½ç§»æ˜¯å¦å‰é€²ï¼ˆpos1 > pos0ï¼‰ï¼Œè‹¥æœªå‰é€²è¦–ç‚ºå£è³‡æ–™ç›´æ¥ä¸ŸéŒ¯ã€‚
    """
    size = p.stat().st_size
    detailed_info = {
        'compute_nodes': 0,
        'comm_nodes': 0,
        'alpha_nodes': 0,
        'timing_info': [],
        'node_types': {},
        'comm_sizes': []
    }

    with p.open("rb") as f:
        # å…ˆè®€ GlobalMetadataï¼ˆé–‹é ­ä¸€å®šæœ‰ï¼‰
        meta = GlobalMetadata()
        before = f.tell()
        decode_message(f, meta)         # å…§éƒ¨æœƒå…ˆè®€ varint32 é•·åº¦ï¼Œå†è®€å°æ‡‰ bytes
        after = f.tell()
        if after == before:
            raise RuntimeError(f"{p.name}: ç„¡æ³•è®€å– GlobalMetadataï¼ˆæª”æ¡ˆæ ¼å¼ä¸å°æˆ–ç‚ºç©ºï¼‰")

        nodes = 0
        total_bytes = 0
        kinds: dict[int, int] = {}

        # é€ Node è®€å–ï¼šä»¥ã€Œæª”æ¡ˆå¤§å°ã€ç‚ºä¸Šé™ï¼Œé¿å…åœ¨ EOF æˆ–å£å°¾å·´è™•ç„¡é™è®€å–
        while f.tell() < size:
            if max_nodes is not None and nodes >= max_nodes:
                break

            pos0 = f.tell()
            node = Node()
            try:
                decode_message(f, node)  # ä¸€æ¨£ï¼šå…ˆè®€é•·åº¦å‰ç¶´ï¼Œå†è®€å…§å®¹
            except Exception:
                # è®€åˆ°å£ç¯€é» / éé æœŸ EOFï¼šç›´æ¥è·³å‡ºï¼ˆå·²è®€åˆ°çš„è³‡æ–™ä»å¯å›å ±ï¼‰
                break
            pos1 = f.tell()

            # é˜²å‘†ï¼šè§£å®Œä¸€ç­†å¾Œ offset æ‡‰è©²å‰é€²ï¼›å¦å‰‡è¡¨ç¤ºæª”æ¡ˆå£æ‰æˆ– decode å‡ºéŒ¯ï¼Œé¿å…å¡æ­»
            if pos1 <= pos0:
                raise RuntimeError(f"{p.name}: è§£ç¢¼å¡ä½ï¼ˆoffset æœªå‰é€² at {pos0}ï¼‰ï¼Œæª”æ¡ˆå¯èƒ½æ¯€æ")

            nodes += 1

            # æŠ½å–å¸¸ç”¨å±¬æ€§ï¼ˆcomm_type / comm_sizeï¼‰åšçµ±è¨ˆæ‘˜è¦
            comm_type = None
            comm_size = None
            alpha = None
            duration_micros = None

            for a in node.attr:
                if a.name == "comm_type":
                    comm_type = a.int64_val
                elif a.name == "comm_size":
                    comm_size = a.int64_val
                elif a.name == "alpha":
                    alpha = a.float_val
                elif a.name == "duration_micros":
                    duration_micros = a.float_val

            # è©³ç´°åˆ†æ
            if detailed:
                # ç¯€é»é¡å‹åˆ†æ
                node_type = node.type if hasattr(node, 'type') else 'UNKNOWN'
                detailed_info['node_types'][node_type] = detailed_info['node_types'].get(node_type, 0) + 1

                # è¨ˆç®—/é€šè¨Šç¯€é»åˆ†é¡
                if comm_type is not None:
                    detailed_info['comm_nodes'] += 1
                    if comm_size is not None:
                        detailed_info['comm_sizes'].append(comm_size)
                else:
                    detailed_info['compute_nodes'] += 1

                # Alpha å€¼æª¢æŸ¥
                if alpha is not None:
                    detailed_info['alpha_nodes'] += 1

                # æ™‚é–“è³‡è¨Š
                if duration_micros is not None:
                    detailed_info['timing_info'].append({
                        'node_id': nodes,
                        'duration': duration_micros,
                        'type': 'COMM' if comm_type is not None else 'COMPUTE'
                    })

            if comm_type is not None:
                kinds[comm_type] = kinds.get(comm_type, 0) + 1
            if comm_size is not None:
                total_bytes += comm_size

        return meta, nodes, total_bytes, kinds, detailed_info if detailed else None


def main():
    ap = argparse.ArgumentParser()
    ap.add_argument(
        "--max-nodes", type=int, default=None,
        help="æ¯æª”æœ€å¤šè§£ç¢¼çš„ç¯€é»æ•¸ï¼ˆæŠ½æ¨£é©—è­‰ï¼›é è¨­å…¨é‡ï¼‰"
    )
    ap.add_argument(
        "--validate", action="store_true",
        help="åŸ·è¡Œæ·±åº¦é©—è­‰æª¢æŸ¥ï¼ˆæª¢æŸ¥ç¯€é»ä¸€è‡´æ€§ã€æ™‚åºç­‰ï¼‰"
    )
    args = ap.parse_args()

    # è©³ç´°åˆ†æé è¨­é–‹å•Ÿ
    detailed = True

    # ä»¥ã€Œæ­¤ç¨‹å¼æ‰€åœ¨ç›®éŒ„ã€ç‚ºåŸºæº–å®šä½åˆ° ../../data/chakra/workload_et
    script_dir = Path(__file__).resolve().parent
    trace_dir = (script_dir / "../../data/chakra/workload_et").resolve()

    # åªåƒ allreduce.{num}.etï¼Œä¸¦ä¾ {num} æ•¸å€¼æ’åºï¼ˆå°æ‡‰ rankï¼‰
    all_files = list(trace_dir.glob("allreduce.*.et"))
    files = [p for p in all_files if PATTERN.match(p.name)]
    files.sort(key=lambda p: int(PATTERN.match(p.name).group(1)))

    if not files:
        print(f"[ERR] æ‰¾ä¸åˆ°ç¬¦åˆæ¨£å¼çš„æª”æ¡ˆï¼š{trace_dir}/allreduce.{{num}}.et")
        sys.exit(1)

    print(f"[INFO] æª¢æŸ¥ç›®éŒ„ï¼š{trace_dir}  æª”æ•¸ï¼š{len(files)}")

    all_detailed_info = []

    for p in files:
        meta, nodes, total_bytes, kinds, detailed_info = read_one_et(
            p, max_nodes=args.max_nodes, detailed=detailed or args.validate
        )
        kind_str = ", ".join([f"{COMM_NAMES.get(k, k)}:{v}" for k, v in kinds.items()]) or "N/A"

        rank = int(PATTERN.match(p.name).group(1))
        print(f"ğŸ“ {p.name:20s}  version={meta.version or 'N/A'}  nodes={nodes:4d}  bytes_sum={total_bytes:,}  kinds=({kind_str})")

        # ç‰ˆæœ¬æé†’ï¼ˆåƒ…æç¤ºï¼Œéè‡´å‘½ï¼‰
        if meta.version and meta.version not in ["0.0.4", "0.0.3", "0.0.x"]:
            print(f"  [WARN] æœªçŸ¥çš„ metadata ç‰ˆæœ¬ï¼š{meta.version}")

        # è©³ç´°åˆ†æ (é è¨­é–‹å•Ÿ)
        if detailed and detailed_info:
            print(f"   ğŸ” è©³ç´°åˆ†æ (Rank {rank}):")
            print(f"      è¨ˆç®—ç¯€é»: {detailed_info['compute_nodes']}")
            print(f"      é€šè¨Šç¯€é»: {detailed_info['comm_nodes']}")
            print(f"      å«Alphaç¯€é»: {detailed_info['alpha_nodes']}")

            if detailed_info['comm_sizes']:
                avg_comm = sum(detailed_info['comm_sizes']) / len(detailed_info['comm_sizes'])
                print(f"      å¹³å‡é€šè¨Šå¤§å°: {avg_comm:,.0f} bytes ({avg_comm/1024/1024:.1f} MB)")

            if detailed_info['timing_info']:
                total_time = sum(t['duration'] for t in detailed_info['timing_info'])
                compute_time = sum(t['duration'] for t in detailed_info['timing_info'] if t['type'] == 'COMPUTE')
                comm_time = sum(t['duration'] for t in detailed_info['timing_info'] if t['type'] == 'COMM')
                print(f"      ç¸½åŸ·è¡Œæ™‚é–“: {total_time:,.0f} Î¼s")
                print(f"      è¨ˆç®—æ™‚é–“: {compute_time:,.0f} Î¼s ({compute_time/total_time*100:.1f}%)")
                print(f"      é€šè¨Šæ™‚é–“: {comm_time:,.0f} Î¼s ({comm_time/total_time*100:.1f}%)")

        if args.validate:
            all_detailed_info.append((rank, detailed_info))

    # æ·±åº¦é©—è­‰
    if args.validate and len(all_detailed_info) > 1:
        print(f"\nğŸ” æ·±åº¦é©—è­‰åˆ†æ:")

        # æª¢æŸ¥ ranks é–“çš„ä¸€è‡´æ€§
        ranks = [info[0] for info in all_detailed_info]
        node_counts = [info[1]['compute_nodes'] + info[1]['comm_nodes'] for info in all_detailed_info]
        comm_counts = [info[1]['comm_nodes'] for info in all_detailed_info]

        # æ™ºèƒ½åˆ†æç¯€é»æ•¸å·®ç•°
        print(f"   ç¯€é»æ•¸åˆ†ä½ˆ: {node_counts}")
        if len(set(node_counts)) == 1:
            print("   âœ… æ‰€æœ‰ ranks çš„ç¯€é»æ•¸ç›¸åŒ")
        else:
            max_nodes = max(node_counts)
            min_nodes = min(node_counts)
            diff = max_nodes - min_nodes
            diff_pct = (diff / max_nodes) * 100

            print(f"   ğŸ“Š ç¯€é»æ•¸å·®ç•°åˆ†æ:")
            print(f"      æœ€å¤§: {max_nodes}, æœ€å°: {min_nodes}, å·®ç•°: {diff} ({diff_pct:.1f}%)")

            # åˆ¤æ–·å·®ç•°æ˜¯å¦åˆç†
            if diff <= max_nodes * 0.05:  # å°æ–¼5%çš„å·®ç•°
                print("   âœ… ç¯€é»æ•¸å·®ç•°åœ¨åˆç†ç¯„åœå…§ (â‰¤5%)")
                print("      å¯èƒ½åŸå› : æ•¸æ“šåˆ†å‰²ä¸å‡ã€å‹•æ…‹åœæ­¢ã€ç¶²è·¯åŒæ­¥å»¶é²")
            elif diff <= max_nodes * 0.15:  # å°æ–¼15%çš„å·®ç•°
                print("   âš ï¸  ç¯€é»æ•¸å·®ç•°è¼ƒå¤§ä½†å¯æ¥å— (5-15%)")
                print("      å»ºè­°æª¢æŸ¥: æ•¸æ“šåŠ è¼‰å™¨é…ç½®ã€sampler è¨­å®š")
            else:
                print("   âŒ ç¯€é»æ•¸å·®ç•°éå¤§ (>15%)")
                print("      å¯èƒ½å•é¡Œ: è¨“ç·´æå‰çµ‚æ­¢ã€åš´é‡çš„åŒæ­¥å•é¡Œ")

        # é€šè¨Šç¯€é»åˆ†æ
        print(f"   é€šè¨Šç¯€é»æ•¸: {comm_counts}")
        if len(set(comm_counts)) == 1:
            print("   âœ… æ‰€æœ‰ ranks çš„é€šè¨Šç¯€é»æ•¸ç›¸åŒ")
        else:
            comm_diff = max(comm_counts) - min(comm_counts)
            print(f"   ğŸ“Š é€šè¨Šç¯€é»å·®ç•°: {comm_diff}")
            if comm_diff == diff // 2:  # æ¯æ­¥åŒ…å«1å€‹è¨ˆç®—+1å€‹é€šè¨Šç¯€é»
                print("   âœ… é€šè¨Šç¯€é»å·®ç•°èˆ‡ç¸½ç¯€é»å·®ç•°ä¸€è‡´ (æ­£å¸¸)")
            else:
                print("   âš ï¸  é€šè¨Šç¯€é»å·®ç•°èˆ‡é æœŸä¸ç¬¦ï¼Œå¯èƒ½æœ‰ç•°å¸¸")

        # æ­¥æ•¸æ¨ç®—
        steps = [count // 2 for count in node_counts]  # å‡è¨­æ¯æ­¥2å€‹ç¯€é»
        print(f"   æ¨ä¼°æ­¥æ•¸: {steps}")
        if len(set(steps)) > 1:
            step_diff = max(steps) - min(steps)
            print(f"   ğŸ“Š æ­¥æ•¸å·®ç•°: {step_diff} æ­¥")
            print(f"      é€™åœ¨åˆ†æ•£å¼è¨“ç·´ä¸­æ˜¯æ­£å¸¸ç¾è±¡")

        # æª¢æŸ¥é€šè¨Šå¤§å°ä¸€è‡´æ€§
        all_comm_sizes = [set(info[1]['comm_sizes']) for info in all_detailed_info]
        if len(all_comm_sizes) > 1 and all(sizes == all_comm_sizes[0] for sizes in all_comm_sizes):
            print("   âœ… æ‰€æœ‰ ranks çš„é€šè¨Šå¤§å°ä¸€è‡´")
        else:
            print("   âš ï¸  ä¸åŒ ranks çš„é€šè¨Šå¤§å°å¯èƒ½ä¸ä¸€è‡´")    # é€£çºŒå‘½åæª¢æŸ¥ï¼šrank æ‡‰ç‚ºé€£çºŒï¼ˆ0..N-1ï¼‰
    idxs = [int(PATTERN.match(p.name).group(1)) for p in files]
    expect = list(range(min(idxs), min(idxs) + len(idxs)))
    if sorted(idxs) != expect:
        print(f"[WARN] æª”å index ä¸æ˜¯é€£çºŒçš„ï¼š{sorted(idxs)}")
    else:
        print(f"âœ… æª”å index é€£çºŒæ€§æ­£ç¢º: {sorted(idxs)}")


if __name__ == "__main__":
    main()
